{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import libraries  \nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport string\nimport pprint\nimport matplotlib.pyplot as plt\nimport spacy          \nimport nltk\nimport gensim\nimport gensim.corpora as corpora\nfrom gensim.utils import simple_preprocess\nfrom gensim.models import CoherenceModel\nimport pyLDAvis\nimport pyLDAvis.gensim  \nfrom nltk.corpus import stopwords\nimport warnings","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-29T00:51:40.714849Z","iopub.execute_input":"2022-11-29T00:51:40.715299Z","iopub.status.idle":"2022-11-29T00:51:40.728386Z","shell.execute_reply.started":"2022-11-29T00:51:40.715265Z","shell.execute_reply":"2022-11-29T00:51:40.726777Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## About this Notebook\nThis Notebook contains a comprehensive walkthrough of how we use, a very famous Amazon automotive dataset\nthat contains feature attributes. The dataset used in this notebook has various origin iplications like: flipkart, \nproduct review and so on.\nHere we're performing a simple workshop on this dataset and use it to model various topics and subject of \ninterests in ecommerece business. ","metadata":{}},{"cell_type":"markdown","source":"### Loading the data\nHere, we will load the data into the system and explore to have more in-depth \nknowledge of the significance of data and what it beholds","metadata":{}},{"cell_type":"code","source":"dFrame = pd.read_csv('../input/ecommerce-product-review-data/Product Review Large Data.csv')\ndFrame.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T00:49:16.540149Z","iopub.execute_input":"2022-11-29T00:49:16.540979Z","iopub.status.idle":"2022-11-29T00:49:17.117878Z","shell.execute_reply.started":"2022-11-29T00:49:16.540938Z","shell.execute_reply":"2022-11-29T00:49:17.116655Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                     id       asins   brand                  categories  \\\n0  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n1  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n2  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n3  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n4  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n\n  colors             dateAdded           dateUpdated  \\\n0    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n1    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n2    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n3    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n4    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n\n                  dimension  ean                         keys  ...  \\\n0  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky  ...   \n1  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky  ...   \n2  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky  ...   \n3  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky  ...   \n4  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky  ...   \n\n  reviews.rating                                 reviews.sourceURLs  \\\n0            5.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n1            5.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n2            4.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n3            5.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n4            5.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n\n                                        reviews.text  \\\n0  I initially had trouble deciding between the p...   \n1  Allow me to preface this with a little history...   \n2  I am enjoying it so far. Great for reading. Ha...   \n3  I bought one of the first Paperwhites and have...   \n4  I have to say upfront - I don't like coroporat...   \n\n                                reviews.title reviews.userCity  \\\n0              Paperwhite voyage, no regrets!              NaN   \n1           One Simply Could Not Ask For More              NaN   \n2  Great for those that just want an e-reader              NaN   \n3                    Love / Hate relationship              NaN   \n4                                   I LOVE IT              NaN   \n\n  reviews.userProvince    reviews.username  sizes upc     weight  \n0                  NaN          Cristina M    NaN NaN  205 grams  \n1                  NaN               Ricky    NaN NaN  205 grams  \n2                  NaN       Tedd Gardiner    NaN NaN  205 grams  \n3                  NaN              Dougal    NaN NaN  205 grams  \n4                  NaN  Miljan David Tanic    NaN NaN  205 grams  \n\n[5 rows x 27 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>asins</th>\n      <th>brand</th>\n      <th>categories</th>\n      <th>colors</th>\n      <th>dateAdded</th>\n      <th>dateUpdated</th>\n      <th>dimension</th>\n      <th>ean</th>\n      <th>keys</th>\n      <th>...</th>\n      <th>reviews.rating</th>\n      <th>reviews.sourceURLs</th>\n      <th>reviews.text</th>\n      <th>reviews.title</th>\n      <th>reviews.userCity</th>\n      <th>reviews.userProvince</th>\n      <th>reviews.username</th>\n      <th>sizes</th>\n      <th>upc</th>\n      <th>weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AVpe7AsMilAPnD_xQ78G</td>\n      <td>B00QJDU3KY</td>\n      <td>Amazon</td>\n      <td>Amazon Devices,mazon.co.uk</td>\n      <td>NaN</td>\n      <td>2016-03-08T20:21:53Z</td>\n      <td>2017-07-18T23:52:58Z</td>\n      <td>169 mm x 117 mm x 9.1 mm</td>\n      <td>NaN</td>\n      <td>kindlepaperwhite/b00qjdu3ky</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>https://www.amazon.com/Kindle-Paperwhite-High-...</td>\n      <td>I initially had trouble deciding between the p...</td>\n      <td>Paperwhite voyage, no regrets!</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Cristina M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>205 grams</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AVpe7AsMilAPnD_xQ78G</td>\n      <td>B00QJDU3KY</td>\n      <td>Amazon</td>\n      <td>Amazon Devices,mazon.co.uk</td>\n      <td>NaN</td>\n      <td>2016-03-08T20:21:53Z</td>\n      <td>2017-07-18T23:52:58Z</td>\n      <td>169 mm x 117 mm x 9.1 mm</td>\n      <td>NaN</td>\n      <td>kindlepaperwhite/b00qjdu3ky</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>https://www.amazon.com/Kindle-Paperwhite-High-...</td>\n      <td>Allow me to preface this with a little history...</td>\n      <td>One Simply Could Not Ask For More</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Ricky</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>205 grams</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AVpe7AsMilAPnD_xQ78G</td>\n      <td>B00QJDU3KY</td>\n      <td>Amazon</td>\n      <td>Amazon Devices,mazon.co.uk</td>\n      <td>NaN</td>\n      <td>2016-03-08T20:21:53Z</td>\n      <td>2017-07-18T23:52:58Z</td>\n      <td>169 mm x 117 mm x 9.1 mm</td>\n      <td>NaN</td>\n      <td>kindlepaperwhite/b00qjdu3ky</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>https://www.amazon.com/Kindle-Paperwhite-High-...</td>\n      <td>I am enjoying it so far. Great for reading. Ha...</td>\n      <td>Great for those that just want an e-reader</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Tedd Gardiner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>205 grams</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AVpe7AsMilAPnD_xQ78G</td>\n      <td>B00QJDU3KY</td>\n      <td>Amazon</td>\n      <td>Amazon Devices,mazon.co.uk</td>\n      <td>NaN</td>\n      <td>2016-03-08T20:21:53Z</td>\n      <td>2017-07-18T23:52:58Z</td>\n      <td>169 mm x 117 mm x 9.1 mm</td>\n      <td>NaN</td>\n      <td>kindlepaperwhite/b00qjdu3ky</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>https://www.amazon.com/Kindle-Paperwhite-High-...</td>\n      <td>I bought one of the first Paperwhites and have...</td>\n      <td>Love / Hate relationship</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Dougal</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>205 grams</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AVpe7AsMilAPnD_xQ78G</td>\n      <td>B00QJDU3KY</td>\n      <td>Amazon</td>\n      <td>Amazon Devices,mazon.co.uk</td>\n      <td>NaN</td>\n      <td>2016-03-08T20:21:53Z</td>\n      <td>2017-07-18T23:52:58Z</td>\n      <td>169 mm x 117 mm x 9.1 mm</td>\n      <td>NaN</td>\n      <td>kindlepaperwhite/b00qjdu3ky</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>https://www.amazon.com/Kindle-Paperwhite-High-...</td>\n      <td>I have to say upfront - I don't like coroporat...</td>\n      <td>I LOVE IT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Miljan David Tanic</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>205 grams</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 27 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## The first view on dataFrame \nHere, looking at the dataframe, as we can see its a pretty comprehensive dataFrame consisting of many feature categories and \ndataPoints. Initially, we are only looking at the first five entry and every data point in the dataframe 27 columns and thereare altogether total of 10971 data points","metadata":{}},{"cell_type":"code","source":"print(dFrame.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T00:49:21.377901Z","iopub.execute_input":"2022-11-29T00:49:21.378713Z","iopub.status.idle":"2022-11-29T00:49:21.384732Z","shell.execute_reply.started":"2022-11-29T00:49:21.378674Z","shell.execute_reply":"2022-11-29T00:49:21.383466Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"(10971, 27)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Data Preprocessing\nNow we'll preprocess the data thats given to us before we can pass it for training a machine learning model \nand making any prediction. To remove anamolity, and baises and bugs from the model, data preprocessing is highly recommeded\npre-process in machine learning. During this process, we basically clean data entries, deal with missing values, we normalize the dataset and then finally pass it to the model. But before we can do that, we have to follo these steps to clean our data\n1. Word Tokenization\n2. Getting rid of stop words\n3. Vocabulary Lemmatiation","metadata":{}},{"cell_type":"code","source":"# This method tokenizes the word using gensim process. Learn more about \ndef tokenize(sentences, deacc=True):\n    for sentence in sentences: \n        yield(gensim.utils.simple_preprocess(str(sentence)))  \ndata = dFrame['reviews.text'].values.tolist()\nwordsData = list(tokenize(data)) # recursively provess each invocation","metadata":{"execution":{"iopub.status.busy":"2022-11-29T00:49:41.820103Z","iopub.execute_input":"2022-11-29T00:49:41.820533Z","iopub.status.idle":"2022-11-29T00:49:42.508949Z","shell.execute_reply.started":"2022-11-29T00:49:41.820489Z","shell.execute_reply":"2022-11-29T00:49:42.507590Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# After tokenzation, the bag of word looks something like this\nprint(wordsData[20])","metadata":{"execution":{"iopub.status.busy":"2022-11-29T00:49:51.919073Z","iopub.execute_input":"2022-11-29T00:49:51.919506Z","iopub.status.idle":"2022-11-29T00:49:51.925794Z","shell.execute_reply.started":"2022-11-29T00:49:51.919471Z","shell.execute_reply":"2022-11-29T00:49:51.924478Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"['almost', 'like', 'reading', 'real', 'book', 'don', 'is', 'crisp', 'sharp', 'and', 'easy', 'to', 'read', 've', 'held', 'out', 'from', 'buying', 'reader', 'for', 'years', 'because', 'could', 'never', 'quite', 'get', 'past', 'the', 'fact', 'it', 'wasn', 'book', 'with', 'this', 'new', 'kindle', 'don', 'even', 'notice', 'am', 'immediately', 'immersed', 'wildly', 'better', 'than', 'expected']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Here, we will create a list of stop words. A stop word in Natural Language Processing is basically a \nlist of most commonly used words. For example, in English, “the”, “is” and “and”, would easily qualify as stop words. In NLP and text mining applications, stop words are used to eliminate unimportant words, allowing applications to focus on the important words instead.\n","metadata":{}},{"cell_type":"code","source":"stopWordList =  stopwords.words('english') + list(string.punctuation)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T00:52:37.408861Z","iopub.execute_input":"2022-11-29T00:52:37.409295Z","iopub.status.idle":"2022-11-29T00:52:37.416293Z","shell.execute_reply.started":"2022-11-29T00:52:37.409259Z","shell.execute_reply":"2022-11-29T00:52:37.414798Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"After extreacting the stop words from provided python library, we will move further on removing the stop words from our word bank and \napply the process of lemmatization. Stop words are available in abundance in any human language. By removing these words, we remove the low-level information from our text in order to give more focus to the important information","metadata":{}},{"cell_type":"code","source":"def chopStopWords(words):\n    return [[word for word in simple_preprocess(str(doc)) if word not in words] for doc in words]\n","metadata":{"execution":{"iopub.status.busy":"2022-11-29T00:59:03.382493Z","iopub.execute_input":"2022-11-29T00:59:03.382906Z","iopub.status.idle":"2022-11-29T00:59:03.389326Z","shell.execute_reply.started":"2022-11-29T00:59:03.382872Z","shell.execute_reply":"2022-11-29T00:59:03.387993Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n    \n    textOutput = []\n    for sent in texts:\n        doc = nlp(\" \".join(sent)) \n        textOutput.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n    return textOutput","metadata":{"execution":{"iopub.status.busy":"2022-11-29T00:59:04.186290Z","iopub.execute_input":"2022-11-29T00:59:04.187503Z","iopub.status.idle":"2022-11-29T00:59:04.195119Z","shell.execute_reply.started":"2022-11-29T00:59:04.187433Z","shell.execute_reply":"2022-11-29T00:59:04.194223Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"In the code above, we are performing the process of lemmatization. Lemmatization is a text normalization technique used in Natural Language Processing (NLP), that switches any kind of a word to its base root mode. Lemmatization is responsible for grouping different inflected forms of words into the root form, having the same meaning. Read more here at source: https://www.engati.com/glossary/lemmatization#:~:text=Lemmatization%20is%20a%20text%20normalization,form%2C%20having%20the%20same%20meaning.\n\n\nNow that we have axullary methods for data preprocessing, we'll perform the call funciton and then remove the stop words form\nour word bank which comes from the datasource we're processing","metadata":{}},{"cell_type":"code","source":"dataWordStop = chopStopWords(wordsData)\n# initialize spacy 'en' model, use only tagger since we don't need parsing or NER \nnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n# lemmatization keeping only noun, adj, vb, adv\ndata_lemmatized = lemmatization(dataWordStop, allowed_postags=['NOUN', 'ADJ'])","metadata":{"execution":{"iopub.status.busy":"2022-11-29T01:00:30.715410Z","iopub.execute_input":"2022-11-29T01:00:30.715838Z","iopub.status.idle":"2022-11-29T01:02:57.355069Z","shell.execute_reply.started":"2022-11-29T01:00:30.715802Z","shell.execute_reply":"2022-11-29T01:02:57.353948Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"Now that we've lemmatizationied data and processed it through the python nlp space, lets \ntake a close look at what lemmatizationized data looks like\n","metadata":{}},{"cell_type":"code","source":"print(data_lemmatized[30])","metadata":{"execution":{"iopub.status.busy":"2022-11-29T01:06:31.273235Z","iopub.execute_input":"2022-11-29T01:06:31.273706Z","iopub.status.idle":"2022-11-29T01:06:31.279961Z","shell.execute_reply.started":"2022-11-29T01:06:31.273666Z","shell.execute_reply":"2022-11-29T01:06:31.278822Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"['update', 'review', 'year', 'old', 'kindle', 'keyboard', 'new', 'model', 'basic', 'cheapie', 'kindle', 'kindle', 'touch', 'course', 'kindle', 'fire', 'quasi', 'model', 'excellent', 'choice', 'one', 'right', 'preference', 'ink', 'kindle', 'kindle', 'keyboard', 'kindle', 'touch', 'new', 'flagship', 'model', 'basic', 'kindle', 'same', 'display', 'same', 'sharp', 'typeface', 'high', 'contrast', 'ink', 'paper', 'eyestrain', 'kindle', 'keyboard', 'old', 'model', 'first', 'one', 'kindle', 'keyboard', 'day', 'dozen', 'book', 'new', 'model', 'neat', 'feature', 'experience', 'book', 'well', 'bad', 'year', 'old', 'kindle', 'keyboard', 'page', 'turn', 'smooth', 'new', 'kindle', 'difference', 'enough', 'worth', 'cost', 'opinion', 'touch', 'screen', 'interface', 'kindle', 'touch', 'neat', 'ipad', 'kindle', 'book', 'book', 'nice', 'current', 'kindle', 'model', 'touch', 'screen', 'feature', 'late', 'version', 'tech', 'product', 'own', 'reason', 'cheap', 'kindle', 'excellent', 'choice', 'more']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Now that everything is in place, we'll compare the nonstop, and lemmatised version of the original\nwords that comes from the word bank\nAs we can see below, all the words are properly lemmatised","metadata":{}},{"cell_type":"code","source":"print(' '.join(wordsData[10]), '\\n')","metadata":{"execution":{"iopub.status.busy":"2022-11-29T01:09:57.162601Z","iopub.execute_input":"2022-11-29T01:09:57.163030Z","iopub.status.idle":"2022-11-29T01:09:57.169399Z","shell.execute_reply.started":"2022-11-29T01:09:57.162995Z","shell.execute_reply":"2022-11-29T01:09:57.168159Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"as reviewed by the wife this is the perfect thing for new mommy who loves to read books as soon as had my baby girl had to stop reading my novels because had to give the baby my full attention but how much time do spend laying in bed on my side with the baby while she feeds especially prior to months when feeding took as long as minutes not to mention cluster feeds during growth spurts book was out of the question because it sooo tiring to hold up in side lying breastfeeding position my new kindle was the solution it light easy to disinfect use baby wipes on the case whenever feel like it not clean enough to go on the bed with the baby and you don need to keep finger in the middle of the pages to keep it from closing you know what mean and for some reason it much easier to go through book with kindle compared to an actual book never thought be converted into the kindle culture but here we are \n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Anfter the process of lemmatization\nprint(' '.join(data_lemmatized[10]))","metadata":{"execution":{"iopub.status.busy":"2022-11-29T01:10:36.135191Z","iopub.execute_input":"2022-11-29T01:10:36.135612Z","iopub.status.idle":"2022-11-29T01:10:36.141594Z","shell.execute_reply.started":"2022-11-29T01:10:36.135578Z","shell.execute_reply":"2022-11-29T01:10:36.140339Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"wife perfect thing new mommy book baby girl novel baby full attention much time bed side baby month feeding minute cluster growth spurt book question tiring side position new kindle solution easy use baby wipe case clean bed baby finger middle page reason easy book kindle actual book kindle culture\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Dictionary and Corpus\nOne of the reasons why it’s so hard to learn, practice and experiment with Natural Language Processing is due to the lack of available corpora. Building a gold standard corpus is seriously hard work. Gensim's LDA requires the data in a certain format. Firstly, it needs the corpus as a dicionary of id-word mapping, where each word has a unique numeric ID. This is for computationally efficiency purposes. Secondly, it needs the corpus as a term-document frequency matrix which contains the frequency","metadata":{}},{"cell_type":"code","source":"#dictionary\nid2word = corpora.Dictionary(data_lemmatized)\n#corpus\ncorpus = [id2word.doc2bow(text) for text in data_lemmatized]","metadata":{"execution":{"iopub.status.busy":"2022-11-29T01:12:36.855700Z","iopub.execute_input":"2022-11-29T01:12:36.856137Z","iopub.status.idle":"2022-11-29T01:12:37.322478Z","shell.execute_reply.started":"2022-11-29T01:12:36.856100Z","shell.execute_reply":"2022-11-29T01:12:37.320826Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#Lets take a look and corpus\nprint(corpus[3])","metadata":{"execution":{"iopub.status.busy":"2022-11-29T01:12:49.448350Z","iopub.execute_input":"2022-11-29T01:12:49.448874Z","iopub.status.idle":"2022-11-29T01:12:49.455603Z","shell.execute_reply.started":"2022-11-29T01:12:49.448833Z","shell.execute_reply":"2022-11-29T01:12:49.454231Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"[(6, 2), (24, 1), (25, 5), (32, 1), (33, 1), (41, 1), (47, 2), (50, 6), (72, 4), (76, 3), (77, 1), (80, 1), (81, 1), (93, 1), (94, 1), (95, 1), (101, 1), (102, 2), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 2), (110, 1), (111, 1), (112, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 2), (122, 1), (123, 1), (124, 1), (125, 3), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 1), (139, 1), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1)]\n","output_type":"stream"}]},{"cell_type":"code","source":"#Lets take a look at dictionary \nprint(id2word)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T01:13:07.602620Z","iopub.execute_input":"2022-11-29T01:13:07.603024Z","iopub.status.idle":"2022-11-29T01:13:07.609064Z","shell.execute_reply.started":"2022-11-29T01:13:07.602986Z","shell.execute_reply":"2022-11-29T01:13:07.607716Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Dictionary(6207 unique tokens: ['adjustment', 'auto', 'basis', 'case', 'certain']...)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Readable format of corpus (term,frequency)\n[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]","metadata":{"execution":{"iopub.status.busy":"2022-11-29T01:13:35.012746Z","iopub.execute_input":"2022-11-29T01:13:35.013139Z","iopub.status.idle":"2022-11-29T01:13:35.024812Z","shell.execute_reply.started":"2022-11-29T01:13:35.013106Z","shell.execute_reply":"2022-11-29T01:13:35.023803Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"[[('adjustment', 1),\n  ('auto', 1),\n  ('basis', 1),\n  ('case', 1),\n  ('certain', 1),\n  ('custom', 1),\n  ('day', 2),\n  ('delivery', 1),\n  ('dollar', 1),\n  ('easy', 1),\n  ('expense', 1),\n  ('extra', 1),\n  ('fine', 1),\n  ('friend', 1),\n  ('glad', 1),\n  ('great', 1),\n  ('hard', 1),\n  ('international', 1),\n  ('jump', 1),\n  ('level', 1),\n  ('light', 3),\n  ('model', 1),\n  ('money', 1),\n  ('option', 1),\n  ('page', 1),\n  ('paperwhite', 4),\n  ('party', 1),\n  ('ppi', 1),\n  ('press', 1),\n  ('pricey', 1),\n  ('receptive', 1),\n  ('review', 1),\n  ('same', 1),\n  ('screen', 1),\n  ('sensitive', 1),\n  ('service', 1),\n  ('setting', 3),\n  ('shipping', 2),\n  ('specific', 2),\n  ('thing', 1),\n  ('third', 1),\n  ('time', 3),\n  ('touch', 1),\n  ('tracking', 1),\n  ('trouble', 1),\n  ('voyage', 3),\n  ('week', 1)]]"},"metadata":{}}]},{"cell_type":"markdown","source":"### Insight into the top 10 topics \nwe print the top 10 topics\n","metadata":{}},{"cell_type":"code","source":"# Building lda model for training\nlda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n                                           id2word=id2word,\n                                           num_topics=6, \n                                           random_state=101,\n                                           update_every=1,\n                                           chunksize=999,\n                                           passes=99,\n                                           alpha=0.1,\n                                           per_word_topics=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T01:15:00.505529Z","iopub.execute_input":"2022-11-29T01:15:00.505936Z","iopub.status.idle":"2022-11-29T01:18:30.441183Z","shell.execute_reply.started":"2022-11-29T01:15:00.505902Z","shell.execute_reply":"2022-11-29T01:18:30.439975Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"pprint.pprint(lda_model.print_topics())\ndoc_lda = lda_model[corpus]","metadata":{"execution":{"iopub.status.busy":"2022-11-29T01:18:48.362881Z","iopub.execute_input":"2022-11-29T01:18:48.363308Z","iopub.status.idle":"2022-11-29T01:18:48.376129Z","shell.execute_reply.started":"2022-11-29T01:18:48.363267Z","shell.execute_reply":"2022-11-29T01:18:48.374506Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"[(0,\n  '0.124*\"good\" + 0.064*\"quality\" + 0.063*\"product\" + 0.062*\"sound\" + '\n  '0.047*\"bass\" + 0.023*\"nice\" + 0.023*\"battery\" + 0.021*\"awesome\" + '\n  '0.020*\"price\" + 0.016*\"ear\"'),\n (1,\n  '0.052*\"kindle\" + 0.027*\"fire\" + 0.020*\"year\" + 0.019*\"device\" + 0.019*\"new\" '\n  '+ 0.018*\"book\" + 0.015*\"screen\" + 0.013*\"hdx\" + 0.013*\"model\" + '\n  '0.012*\"last\"'),\n (2,\n  '0.026*\"tv\" + 0.020*\"fire\" + 0.019*\"other\" + 0.017*\"box\" + 0.015*\"more\" + '\n  '0.014*\"roku\" + 0.014*\"review\" + 0.013*\"amazon\" + 0.013*\"content\" + '\n  '0.012*\"device\"'),\n (3,\n  '0.047*\"headphone\" + 0.043*\"nice\" + 0.020*\"apple\" + 0.016*\"people\" + '\n  '0.016*\"more\" + 0.015*\"case\" + 0.014*\"earbud\" + 0.013*\"year\" + '\n  '0.012*\"magnet\" + 0.010*\"free\"'),\n (4,\n  '0.019*\"bad\" + 0.018*\"month\" + 0.017*\"voice\" + 0.017*\"great\" + 0.016*\"prime\" '\n  '+ 0.015*\"speaker\" + 0.015*\"music\" + 0.015*\"problem\" + 0.015*\"echo\" + '\n  '0.015*\"tap\"'),\n (5,\n  '0.117*\"earphone\" + 0.042*\"price\" + 0.030*\"range\" + 0.028*\"quality\" + '\n  '0.028*\"boat\" + 0.026*\"super\" + 0.021*\"well\" + 0.020*\"great\" + 0.016*\"such\" '\n  '+ 0.015*\"low\"')]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Model analysis and evluation\nNow that we have defined and procceeded the model, afficiency. Its time to \nevaluate the model. Here we'll be using coherence score to judge how well the lda_model performs","metadata":{}},{"cell_type":"code","source":"coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\ncoherence_lda = coherence_model_lda.get_coherence()\nprint('\\nCoherence Score: ', coherence_lda)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T01:22:30.583670Z","iopub.execute_input":"2022-11-29T01:22:30.584129Z","iopub.status.idle":"2022-11-29T01:22:31.950347Z","shell.execute_reply.started":"2022-11-29T01:22:30.584088Z","shell.execute_reply":"2022-11-29T01:22:31.949053Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"\nCoherence Score:  0.565607602946545\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Visualization\nLets dig further into analysis with some visualization.\nFor interactive visualization, here we'll use pyLDAvis library","metadata":{}},{"cell_type":"code","source":"pyLDAvis.enable_notebook()\nvis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\nvis","metadata":{"execution":{"iopub.status.busy":"2022-11-29T01:23:50.562447Z","iopub.execute_input":"2022-11-29T01:23:50.562905Z","iopub.status.idle":"2022-11-29T01:23:54.270243Z","shell.execute_reply.started":"2022-11-29T01:23:50.562868Z","shell.execute_reply":"2022-11-29T01:23:54.269075Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pyLDAvis/_prepare.py:248: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n  by='saliency', ascending=False).head(R).drop('saliency', 1)\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\ntopic                                                \n0      0.246370 -0.095558       1        1  37.264994\n1     -0.166306 -0.080461       2        1  15.348285\n2     -0.133739  0.049432       3        1  15.120087\n3     -0.138215  0.179974       4        1  12.177818\n4     -0.038740 -0.200320       5        1  11.969503\n5      0.230629  0.146934       6        1   8.119312, topic_info=          Term         Freq        Total Category  logprob  loglift\n125       good  8027.000000  8027.000000  Default  30.0000  30.0000\n2540  earphone  1550.000000  1550.000000  Default  29.0000  29.0000\n874      sound  3848.000000  3848.000000  Default  28.0000  28.0000\n2524      bass  2843.000000  2843.000000  Default  27.0000  27.0000\n406    quality  4446.000000  4446.000000  Default  26.0000  26.0000\n...        ...          ...          ...      ...      ...      ...\n80       other   147.012034  1018.559455   Topic6  -4.4996   0.5753\n31      review   128.027374  1006.662535   Topic6  -4.6379   0.4488\n217      worth   102.887916   556.425389   Topic6  -4.8565   0.8230\n125       good   187.444948  8027.427456   Topic6  -4.2566  -1.2462\n32        same    85.074378   431.326410   Topic6  -5.0466   0.8876\n\n[402 rows x 6 columns], token_table=      Topic      Freq     Term\nterm                          \n543       3  0.982877  ability\n265       2  0.187663     able\n265       4  0.389762     able\n265       5  0.421521     able\n146       5  0.964192  account\n...     ...       ...      ...\n217       3  0.089859    worth\n217       6  0.185110    worth\n95        2  0.616706     year\n95        3  0.069061     year\n95        4  0.312594     year\n\n[593 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 2, 3, 4, 5, 6])","text/html":"\n<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v1.0.0.css\">\n\n\n<div id=\"ldavis_el271401164527291685618773790\"></div>\n<script type=\"text/javascript\">\n\nvar ldavis_el271401164527291685618773790_data = {\"mdsDat\": {\"x\": [0.24637039600670402, -0.16630575853362545, -0.13373868722172214, -0.1382147268981751, -0.038739730931136356, 0.23062850757795436], \"y\": [-0.09555799704109062, -0.0804611189066613, 0.04943208113745595, 0.17997362451158236, -0.2003204645255597, 0.14693387482427311], \"topics\": [1, 2, 3, 4, 5, 6], \"cluster\": [1, 1, 1, 1, 1, 1], \"Freq\": [37.26499445517494, 15.348285244963966, 15.120087276244346, 12.177818440643087, 11.969502862067628, 8.119311720906028]}, \"tinfo\": {\"Term\": [\"good\", \"earphone\", \"sound\", \"bass\", \"quality\", \"kindle\", \"nice\", \"headphone\", \"product\", \"price\", \"range\", \"fire\", \"boat\", \"awesome\", \"tv\", \"ear\", \"year\", \"super\", \"backup\", \"bad\", \"apple\", \"month\", \"book\", \"box\", \"device\", \"well\", \"voice\", \"great\", \"music\", \"low\", \"bass\", \"awesome\", \"ear\", \"backup\", \"design\", \"bud\", \"headset\", \"delivery\", \"build\", \"wire\", \"noise\", \"clarity\", \"realme\", \"vocal\", \"loud\", \"normal\", \"segment\", \"colour\", \"hrs\", \"balanced\", \"bullet\", \"tangle\", \"basshead\", \"neckband\", \"sound\", \"deep\", \"charging\", \"fabulous\", \"comfort\", \"stylish\", \"good\", \"flipkart\", \"product\", \"quality\", \"superb\", \"battery\", \"excellent\", \"clear\", \"decent\", \"thank\", \"value\", \"money\", \"nice\", \"price\", \"base\", \"call\", \"day\", \"boat\", \"range\", \"amazing\", \"great\", \"headphone\", \"bad\", \"worth\", \"time\", \"low\", \"paperwhite\", \"right\", \"page\", \"keyboard\", \"pain\", \"ink\", \"eye\", \"edge\", \"reading\", \"voyage\", \"left\", \"inch\", \"resolution\", \"nexus\", \"following\", \"text\", \"email\", \"oasis\", \"night\", \"operating\", \"killer\", \"contrast\", \"consistent\", \"result\", \"font\", \"excited\", \"current\", \"ppi\", \"leap\", \"carousel\", \"kindle\", \"book\", \"mini\", \"model\", \"blue\", \"previous\", \"display\", \"new\", \"hd\", \"last\", \"year\", \"fire\", \"screen\", \"hdx\", \"video\", \"ipad\", \"version\", \"size\", \"old\", \"device\", \"light\", \"side\", \"power\", \"generation\", \"button\", \"time\", \"feature\", \"review\", \"more\", \"tablet\", \"first\", \"box\", \"roku\", \"smart\", \"streaming\", \"comcast\", \"response\", \"casual\", \"huge\", \"controller\", \"firetv\", \"additional\", \"channel\", \"airdope\", \"negative\", \"secondary\", \"navigation\", \"ability\", \"niche\", \"immediate\", \"fabric\", \"bed\", \"site\", \"connect\", \"chromecast\", \"drop\", \"answer\", \"scratch\", \"saver\", \"compact\", \"pleasant\", \"tv\", \"early\", \"interface\", \"own\", \"smartphone\", \"note\", \"option\", \"content\", \"fan\", \"other\", \"game\", \"fire\", \"search\", \"many\", \"past\", \"most\", \"amazon\", \"feature\", \"review\", \"more\", \"easy\", \"user\", \"device\", \"sure\", \"way\", \"app\", \"tablet\", \"big\", \"thing\", \"point\", \"free\", \"remote\", \"apple\", \"time\", \"product\", \"good\", \"quality\", \"great\", \"earpod\", \"iphone\", \"android\", \"complaint\", \"title\", \"audiophile\", \"download\", \"ad\", \"cancelling\", \"gig\", \"capacity\", \"metal\", \"specific\", \"assumption\", \"chance\", \"card\", \"common\", \"offering\", \"number\", \"bag\", \"crazy\", \"secure\", \"description\", \"validity\", \"outside\", \"ignorance\", \"step\", \"section\", \"public\", \"stock\", \"cord\", \"set\", \"magnet\", \"headphone\", \"case\", \"apple\", \"people\", \"earbud\", \"end\", \"large\", \"cover\", \"flat\", \"nice\", \"regular\", \"simple\", \"free\", \"more\", \"year\", \"prime\", \"hdx\", \"thing\", \"amazon\", \"tablet\", \"able\", \"great\", \"version\", \"screen\", \"high\", \"most\", \"review\", \"device\", \"tap\", \"waste\", \"replacement\", \"alexa\", \"portable\", \"category\", \"team\", \"sling\", \"command\", \"bt\", \"gift\", \"damage\", \"account\", \"feedback\", \"driver\", \"audible\", \"defective\", \"kind\", \"physical\", \"genre\", \"request\", \"pure\", \"policy\", \"weather\", \"compatible\", \"shopping\", \"process\", \"none\", \"difficult\", \"feeling\", \"echo\", \"room\", \"speaker\", \"problem\", \"top\", \"return\", \"voice\", \"month\", \"service\", \"connection\", \"button\", \"prime\", \"bad\", \"issue\", \"phone\", \"only\", \"didn\", \"movie\", \"music\", \"available\", \"remote\", \"day\", \"great\", \"device\", \"time\", \"amazon\", \"able\", \"thing\", \"side\", \"mic\", \"easy\", \"product\", \"other\", \"call\", \"earphone\", \"super\", \"mi\", \"mid\", \"pair\", \"durable\", \"min\", \"musician\", \"penny\", \"awsome\", \"ondemand\", \"airpod\", \"uncomfortable\", \"disconnect\", \"flipcart\", \"just\", \"refund\", \"sturdy\", \"cute\", \"redmi\", \"aged\", \"cx\", \"frequency\", \"delicate\", \"disturbance\", \"mom\", \"cancelation\", \"listening\", \"disconnected\", \"indicator\", \"such\", \"company\", \"suggestion\", \"fit\", \"brand\", \"range\", \"boat\", \"tight\", \"con\", \"well\", \"neck\", \"price\", \"fitting\", \"cheap\", \"jbl\", \"point\", \"low\", \"high\", \"amazing\", \"pro\", \"music\", \"great\", \"item\", \"fine\", \"quality\", \"phone\", \"perfect\", \"other\", \"review\", \"worth\", \"good\", \"same\"], \"Freq\": [8027.0, 1550.0, 3848.0, 2843.0, 4446.0, 1368.0, 2317.0, 1365.0, 4263.0, 1938.0, 820.0, 1174.0, 806.0, 1252.0, 674.0, 944.0, 825.0, 347.0, 861.0, 803.0, 541.0, 648.0, 483.0, 413.0, 1172.0, 753.0, 556.0, 1445.0, 813.0, 649.0, 2842.223994652064, 1251.7204155141408, 943.3036226143035, 860.7754445895259, 629.2055748759284, 605.2666696907371, 507.9685295969458, 391.7609851490724, 330.6196570133171, 296.38468959451615, 269.77617421084875, 255.93517293548862, 193.83375655359302, 141.4135150627674, 123.56346188459969, 117.73208282017164, 102.09390937942187, 101.24107089804883, 98.91090825478001, 85.2551803472758, 68.57889505729706, 69.12841050881708, 61.674749761364154, 60.25825276933707, 3773.4408924912873, 57.22297275209187, 56.12638737551875, 55.872674606566086, 55.438784494562896, 54.036596659565696, 7518.200424402332, 554.8347684414618, 3841.4214393156767, 3895.288838763309, 256.05004199947956, 1415.5264714194836, 488.5475437235636, 473.77978686916754, 217.569329642249, 241.56302592909284, 303.59393198718993, 511.6693886209532, 1421.7956138574868, 1191.6749094114373, 212.04390997002128, 304.78607666385886, 467.68949299104787, 437.8658877828544, 425.81475743346084, 361.67512903327855, 495.4358425734303, 432.122491127272, 364.6871977530745, 320.95804633398274, 319.6443321335232, 308.003004167233, 270.87387193137545, 259.16934904901865, 209.47184391077255, 139.2424592580644, 100.34623681201633, 94.73972927011857, 78.68299274630536, 75.16101507460785, 66.00301726884356, 65.9103282833769, 64.85648595835212, 54.763488011692836, 54.36947831304514, 52.60010263777649, 50.65009988429691, 48.3491860637599, 48.16477166236769, 43.714707679564206, 41.412853578175884, 41.25707262091213, 39.96490548865793, 37.82497473647226, 37.51900210750053, 34.45041738239464, 33.07997114149726, 32.129344289735876, 30.807128925446904, 30.41901417640882, 30.416670751996108, 30.416231177975835, 1296.7915673909179, 447.6733608163233, 105.33160006349341, 316.75757464801535, 152.81021705781978, 104.12708573753322, 184.1483164667208, 470.03222640248566, 138.21415880359504, 295.049511498754, 509.2090193390889, 675.573731287814, 370.35542297922296, 334.16025771103983, 289.61388471837927, 148.564223130613, 201.46407449500796, 155.99573720557677, 141.50749394085403, 476.30326506393084, 224.24583939953447, 200.49104974581627, 124.8567677389453, 123.44848902144224, 191.72565267296585, 258.2465347150697, 212.22223817801213, 228.72989031403782, 218.8723934209678, 166.91104132311267, 149.7573376429084, 412.00371856373425, 340.2807599304625, 132.18817957278569, 131.25218561816808, 119.21719267123272, 97.66889000625744, 77.13112699985322, 76.85196346189656, 76.34452270478566, 70.667480481935, 69.47191582807005, 67.46862836856153, 61.32707068277459, 58.709098058020835, 55.138400708592364, 55.28110264860637, 53.89166295549892, 52.63422255690443, 51.746528161646076, 49.35253104965546, 48.575258589652314, 47.21171516901928, 47.47713618895851, 46.41814497740239, 45.519942947332716, 44.988231962763244, 44.929249832532776, 43.58332333347341, 40.46579928113002, 38.75124522239621, 645.2850496710444, 102.1218099804148, 104.66345312696492, 195.2221272022881, 125.79619948334313, 95.39142325259739, 263.0726323862086, 316.64505137140293, 60.521131651381175, 462.93404095473346, 199.0561061896773, 498.283422200139, 120.25836621491692, 218.3380519746986, 94.27242323688547, 195.4352394725116, 321.16755574814266, 268.99854839841413, 337.2805778250555, 360.4339675923282, 226.08924510034046, 179.77722321960647, 295.29808003674805, 117.9838762420795, 147.31308248483782, 165.0821812238039, 177.0018540258067, 147.79662869684833, 183.0859466498171, 135.8212631361021, 151.30341416052212, 131.46337072392836, 148.59868472127272, 155.15588474978452, 176.6134959728184, 152.53051319003808, 143.17518507311334, 135.84028241395927, 171.7598496474384, 156.59965799904867, 109.1982407285771, 106.42444522099885, 105.07042442802177, 101.37639738250283, 92.0623918023775, 91.2060941042062, 84.61494945670992, 78.73947577687487, 78.39499987863769, 77.67799849581363, 73.11589403453583, 69.89556869893822, 70.0504419584836, 69.90841552035431, 67.22850205220041, 64.67912171340802, 63.2105281535263, 61.99452407520165, 62.02393641319382, 59.78489850861724, 58.234253441366754, 56.66168886040921, 56.44162525788509, 55.27256912851827, 53.57172573278067, 52.43221590682172, 49.50487293536381, 48.46205842255894, 182.05487934725042, 136.30054376534622, 230.6311825524204, 932.0745980723896, 300.57447065633096, 391.8232673916664, 321.4266403210211, 278.8345445182651, 149.53481164163105, 121.55422210052718, 168.92146433150353, 90.76247455935555, 847.512079907687, 103.54765340623143, 144.0301449934642, 198.152071308029, 310.845996354933, 258.2325113821756, 183.13510254751571, 176.67811733459908, 189.73325959159942, 195.27974192745359, 155.13601654005083, 134.98239798679464, 193.52034178656305, 128.4904801368595, 144.50046523151335, 139.27219233342467, 125.43257631905753, 145.07863224869948, 122.4903816644451, 283.0837050546309, 99.62531979760088, 94.3866647068004, 93.9857134961166, 88.81502023941023, 81.47140080560916, 79.29613174326643, 75.65649583424877, 68.41922341261716, 65.99558127113116, 63.654643886995785, 49.48273080255412, 42.472822680913346, 42.25850770689702, 42.00985765876125, 39.542045773684414, 38.701117967226025, 37.349929277789684, 36.47741565499807, 35.43965824485314, 33.482157187982416, 33.37241844077365, 31.742875913874734, 30.827615986494724, 28.876637322373604, 27.86475608088865, 27.334750941125673, 27.34054912806703, 27.162174286184047, 26.838806176727278, 284.2706761041288, 82.43210180966034, 293.55954412223895, 284.42844853939755, 101.88204498659037, 61.79792548983043, 334.164269974918, 350.8233464501092, 139.72178484666586, 103.28305404111207, 278.9524537244009, 304.05398097662203, 378.97178688644726, 192.68177054055272, 220.59192683383495, 135.72800094622164, 89.70154803917482, 186.28827280338436, 286.4223528568809, 147.48757767264163, 140.51907414514199, 251.8852639109809, 323.8702496996981, 277.749100640068, 252.26802597766545, 234.43885085914243, 146.22138441033817, 200.66559698980478, 151.5371640143617, 133.0973131316536, 137.46597683368432, 212.00490732367058, 154.95793993360087, 115.56232448791853, 1549.0847758657103, 346.3300129486584, 116.66273303334512, 111.16365757734089, 89.54604242185756, 72.07174950262497, 69.24169558221601, 39.68079861501046, 38.64760911764883, 30.832641325200616, 29.16708463801439, 27.10020361057127, 25.88752047610897, 24.997025309487476, 24.06163671388113, 21.410295661895038, 19.82108798754536, 17.607302330417102, 15.237492295852325, 14.760436473803853, 14.658579270870394, 14.1726239178771, 13.855120562103112, 13.75540546810619, 13.517241761800495, 13.552019077482608, 13.35461704007785, 12.983918235709467, 12.751333098507011, 12.632654719503247, 214.5769894648361, 87.62049746485118, 18.81148632812833, 124.81569512442107, 134.15653438967914, 393.7261643606686, 367.4059748388432, 19.46606307588444, 70.44573020209342, 281.4275678814694, 42.6969465168062, 556.7094668034107, 28.506526616994794, 117.62133833227803, 68.77816846398312, 119.09858347023518, 196.74838464360298, 164.16191511127198, 187.1058945526879, 78.53765989822124, 189.08976770385695, 258.6510024923244, 98.36229137438124, 90.48274307843725, 374.7397673689803, 118.9025504729775, 110.76290610877659, 147.01203388763315, 128.02737399075465, 102.88791614673063, 187.4449483559514, 85.07437846700368], \"Total\": [8027.0, 1550.0, 3848.0, 2843.0, 4446.0, 1368.0, 2317.0, 1365.0, 4263.0, 1938.0, 820.0, 1174.0, 806.0, 1252.0, 674.0, 944.0, 825.0, 347.0, 861.0, 803.0, 541.0, 648.0, 483.0, 413.0, 1172.0, 753.0, 556.0, 1445.0, 813.0, 649.0, 2843.3694110146926, 1252.868155956556, 944.4577463951713, 861.9217369494281, 630.3551335835682, 606.4223797896948, 509.11419073850124, 392.9088137045465, 331.77056323414354, 297.5309530054145, 270.9313714353731, 257.0870657314043, 194.97817586537124, 142.55787987926266, 124.71642146911721, 118.90734406187592, 103.23793607319661, 102.38804162397027, 100.05530732154068, 86.4038115404556, 69.73005109482874, 70.29569862157022, 62.82941503400869, 61.40276393328731, 3848.327069552881, 58.36857692936117, 57.26990805709319, 57.02497883443758, 56.58413483506383, 55.18510318392227, 8027.427456171504, 587.6555517383131, 4263.8974386861155, 4446.715003806843, 271.9425446245159, 1593.809956643222, 535.7354077183338, 527.0709607236845, 237.02069321007244, 265.994813787122, 346.8622211712453, 661.4374147578797, 2317.751862033716, 1938.7409663155026, 253.353255521398, 421.2713872868009, 835.1190389357722, 806.2541628910265, 820.5276553369066, 673.240551181774, 1445.1371975716509, 1365.0979416693908, 803.161933748539, 556.4253886855091, 985.724869171935, 649.69723616856, 271.91741577141136, 260.21893254799915, 210.51569436086405, 140.28592141707927, 101.40179230255062, 95.78296667910813, 79.72954443218727, 76.20575498849371, 67.04657719622838, 66.9536056944305, 65.90500313932579, 55.80837006540199, 55.41570731619396, 53.64388675140238, 51.69222893224718, 49.393254223668464, 49.20796968363804, 44.761490557525846, 42.46208090965413, 42.302757353523255, 41.0102471715153, 38.86923219562165, 38.56136650040108, 35.505736186168036, 34.12353746134893, 33.176225191230756, 31.856783357758296, 31.46216417514841, 31.46094023860602, 31.4606330923348, 1368.5508814747996, 483.60648834527143, 112.28079255554631, 383.61909905909687, 176.4155460156278, 117.49705160187222, 218.8923490864369, 650.7304001096353, 168.37607127652143, 412.58816722882557, 825.3527633197413, 1174.64438534275, 606.9761255491055, 544.1718493410361, 514.3498154237816, 217.6578079998786, 330.7549249908893, 239.24123049613934, 210.36293447449478, 1172.1620752328581, 427.9001401198028, 398.25397355904767, 192.63618703822857, 196.2991666915371, 505.81934527602243, 985.724869171935, 678.3112086308568, 1006.6625349781286, 1137.2403174941069, 499.5905240918078, 399.48093100097424, 413.0486463326008, 341.3232066651452, 133.2323249971716, 132.2960144217116, 120.25973498587999, 98.71513574218594, 78.1756036029984, 77.90213030598814, 77.39033715461542, 71.71053890626338, 70.52012035121435, 68.51157611520156, 62.38306330033799, 59.754887998276054, 56.18059572936095, 56.330796023811516, 54.940730797229484, 53.67606429546051, 52.78831755500035, 50.39854326244192, 49.62583924270103, 48.25862905508449, 48.53334689225932, 47.46062899618982, 46.56814013202628, 46.035488281697155, 45.97547704152775, 44.63018696348955, 41.5114048337145, 39.79525949995743, 674.1090441792923, 110.00862928221511, 113.56726244191188, 227.54508392097617, 141.59918508632865, 105.94385553587293, 392.5184218630915, 497.1257562361203, 65.48594105077196, 1018.5594547599766, 328.205274018723, 1174.64438534275, 169.76967221998478, 389.246908955648, 121.35073656038347, 344.82832151531227, 861.5298058663324, 678.3112086308568, 1006.6625349781286, 1137.2403174941069, 529.325773047329, 371.2018626440197, 1172.1620752328581, 193.3907239988008, 321.81837952848724, 417.7458486961405, 499.5905240918078, 329.123693850982, 789.3073790975557, 301.16638114539694, 447.2701228017008, 272.802780012197, 541.2224205898498, 985.724869171935, 4263.8974386861155, 8027.427456171504, 4446.715003806843, 1445.1371975716509, 172.8160302283009, 157.65871541476383, 110.26171338281324, 107.48579318616979, 106.13263191528682, 102.43402571084431, 93.12341614542466, 92.26651396529276, 85.66982012891559, 79.794847536659, 79.45293748711144, 78.7355237292001, 74.17610006619628, 70.95049519033608, 71.11557380704924, 70.97262392400523, 68.28762357607937, 65.73686478882598, 64.2854477528417, 63.05276231386741, 63.08360796811409, 60.842120497932555, 59.29463225564447, 57.71780537456924, 57.498789072570105, 56.32830971907562, 54.63397997415443, 53.4954563066686, 50.56231883095045, 49.518113471662595, 187.4537792905506, 146.9889497450047, 266.16710158330983, 1365.0979416693908, 389.932003538002, 541.2224205898498, 432.28681295144406, 385.08672321666296, 185.62217214209363, 150.25725029209428, 232.27971092271164, 103.84075025610021, 2317.751862033716, 139.64743817025118, 245.46711233956756, 447.2701228017008, 1137.2403174941069, 825.3527633197413, 590.6559424402277, 544.1718493410361, 789.3073790975557, 861.5298058663324, 499.5905240918078, 346.3650063058299, 1445.1371975716509, 330.7549249908893, 606.9761255491055, 538.444179218762, 344.82832151531227, 1006.6625349781286, 1172.1620752328581, 284.16244487217597, 100.70328582198736, 95.46758045053976, 95.06342433112623, 89.8925992547276, 82.55648082578463, 80.37975307755907, 76.7341388489643, 69.49719959963406, 67.07969375002699, 64.73451301835529, 50.56507193844268, 43.55980902237696, 43.34265759935848, 43.10355371992122, 40.62416758426599, 39.780871116196906, 38.44525875607983, 37.57542986070597, 36.51778742319122, 34.560654711786874, 34.4619908651566, 32.821083990337804, 31.905265366038684, 29.960878280185675, 28.947272882378673, 28.41543607300939, 28.425970912132176, 28.244721071407564, 27.921627651317447, 302.1454681218535, 92.08300691539296, 374.7317832762017, 414.9406357358411, 130.38508785645607, 73.26441755466696, 556.4445969196447, 648.3414570708655, 205.32071902927024, 143.64602775500958, 505.81934527602243, 590.6559424402277, 803.161933748539, 365.40017129285, 464.54738038469975, 237.4796407661208, 130.54206477021287, 400.0484181458898, 813.3214397642233, 294.81337488396974, 272.802780012197, 835.1190389357722, 1445.1371975716509, 1172.1620752328581, 985.724869171935, 861.5298058663324, 346.3650063058299, 789.3073790975557, 398.25397355904767, 353.82095810474607, 529.325773047329, 4263.8974386861155, 1018.5594547599766, 421.2713872868009, 1550.2245139716701, 347.4699082369493, 117.80212470563752, 112.30406428038124, 90.68815960085398, 73.21616739908103, 70.38346361738309, 40.824156077113045, 39.787430908348355, 31.972756604872213, 30.312320546729705, 28.24097652285964, 27.028419372914133, 26.140777700830675, 25.201518960467684, 22.551810077374775, 20.97548041709544, 18.759649263358916, 16.39351026169536, 15.900768362531425, 15.803926060548884, 15.312678330404779, 14.994085528956221, 14.89793038756452, 14.65714990825468, 14.702883613192046, 14.495938663081592, 14.133160675568757, 13.895932487920106, 13.776801825697008, 312.0833201855419, 124.30879534165223, 21.718684368805228, 197.73336457092174, 218.82689176770796, 820.5276553369066, 806.2541628910265, 22.945575007527374, 119.79926842405945, 753.4691589481102, 64.08256703246627, 1938.7409663155026, 38.18858817915931, 262.29630034500127, 127.99880876335182, 301.16638114539694, 649.69723616856, 538.444179218762, 673.240551181774, 172.48838791610348, 813.3214397642233, 1445.1371975716509, 276.4155263078182, 247.74003462226847, 4446.715003806843, 464.54738038469975, 441.03380211667286, 1018.5594547599766, 1006.6625349781286, 556.4253886855091, 8027.427456171504, 431.32641023441414], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.0616, -3.8816, -4.1645, -4.2561, -4.5695, -4.6083, -4.7835, -5.0433, -5.213, -5.3223, -5.4163, -5.469, -5.7469, -6.0622, -6.1972, -6.2455, -6.388, -6.3964, -6.4197, -6.5683, -6.7859, -6.778, -6.892, -6.9153, -2.7782, -6.967, -6.9863, -6.9908, -6.9986, -7.0243, -2.0888, -4.6953, -2.7603, -2.7464, -5.4686, -3.7587, -4.8225, -4.8532, -5.6314, -5.5268, -5.2982, -4.7762, -3.7542, -3.9308, -5.6571, -5.2943, -4.8661, -4.932, -4.9599, -5.1232, -4.8085, -4.9452, -5.1149, -5.2426, -5.2467, -5.2838, -4.5252, -4.5694, -4.7823, -5.1907, -5.5182, -5.5757, -5.7614, -5.8072, -5.9372, -5.9386, -5.9547, -6.1238, -6.1311, -6.1642, -6.2019, -6.2484, -6.2522, -6.3492, -6.4033, -6.4071, -6.4389, -6.4939, -6.502, -6.5874, -6.6279, -6.6571, -6.6991, -6.7118, -6.7119, -6.7119, -2.9592, -4.0228, -5.4698, -4.3687, -5.0977, -5.4813, -4.9111, -3.9741, -5.1981, -4.4397, -3.894, -3.6113, -4.2124, -4.3153, -4.4583, -5.1259, -4.8213, -5.077, -5.1745, -3.9608, -4.7141, -4.8261, -5.2997, -5.311, -4.8708, -4.573, -4.7692, -4.6943, -4.7384, -5.0094, -5.1179, -4.0909, -4.2821, -5.2277, -5.2348, -5.3309, -5.5303, -5.7664, -5.77, -5.7766, -5.8539, -5.871, -5.9002, -5.9957, -6.0393, -6.102, -6.0995, -6.1249, -6.1485, -6.1655, -6.2129, -6.2288, -6.2573, -6.2516, -6.2742, -6.2937, -6.3055, -6.3068, -6.3372, -6.4114, -6.4547, -3.6422, -5.4857, -5.4611, -4.8378, -5.2772, -5.5539, -4.5395, -4.3541, -6.0089, -3.9743, -4.8183, -3.9007, -5.3223, -4.7258, -5.5657, -4.8367, -4.3399, -4.5172, -4.291, -4.2246, -4.691, -4.9202, -4.4239, -5.3413, -5.1193, -5.0054, -4.9357, -5.1161, -4.9019, -5.2006, -5.0926, -5.2332, -5.1106, -5.0675, -4.9379, -5.0845, -5.1478, -5.2004, -4.7494, -4.8418, -5.2023, -5.228, -5.2409, -5.2766, -5.373, -5.3824, -5.4574, -5.5293, -5.5337, -5.5429, -5.6034, -5.6485, -5.6463, -5.6483, -5.6874, -5.726, -5.749, -5.7684, -5.768, -5.8047, -5.831, -5.8584, -5.8623, -5.8832, -5.9145, -5.936, -5.9934, -6.0147, -4.6912, -4.9806, -4.4547, -3.0581, -4.1898, -3.9247, -4.1227, -4.2649, -4.888, -5.0951, -4.7661, -5.3872, -3.1532, -5.2555, -4.9255, -4.6065, -4.1562, -4.3416, -4.6853, -4.7212, -4.6499, -4.6211, -4.8512, -4.9903, -4.6301, -5.0396, -4.9222, -4.9591, -5.0637, -4.9182, -5.0875, -4.2325, -5.2768, -5.3308, -5.3351, -5.3917, -5.478, -5.505, -5.552, -5.6526, -5.6886, -5.7248, -5.9766, -6.1294, -6.1344, -6.1403, -6.2009, -6.2224, -6.2579, -6.2815, -6.3104, -6.3672, -6.3705, -6.4206, -6.4498, -6.5152, -6.5509, -6.5701, -6.5699, -6.5764, -6.5884, -4.2283, -5.4663, -4.1962, -4.2277, -5.2544, -5.7544, -4.0666, -4.0179, -4.9386, -5.2408, -4.2472, -4.161, -3.9408, -4.6172, -4.4819, -4.9676, -5.3817, -4.6509, -4.2208, -4.8845, -4.9329, -4.3493, -4.0979, -4.2515, -4.3477, -4.421, -4.8931, -4.5766, -4.8574, -4.9872, -4.9549, -4.5216, -4.8351, -5.1284, -2.1447, -3.6427, -4.7308, -4.7791, -4.9954, -5.2125, -5.2525, -5.8092, -5.8356, -6.0615, -6.1171, -6.1906, -6.2364, -6.2714, -6.3095, -6.4262, -6.5034, -6.6218, -6.7664, -6.7982, -6.8051, -6.8388, -6.8615, -6.8687, -6.8861, -6.8836, -6.8983, -6.9264, -6.9445, -6.9538, -4.1214, -5.0171, -6.5556, -4.6633, -4.5911, -3.5145, -3.5836, -6.5214, -5.2353, -3.8502, -5.736, -3.1681, -6.14, -4.7226, -5.2592, -4.7102, -4.2082, -4.3893, -4.2584, -5.1265, -4.2479, -3.9346, -4.9015, -4.985, -3.5639, -4.7118, -4.7827, -4.4996, -4.6379, -4.8565, -4.2566, -5.0466], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.9867, 0.9862, 0.9859, 0.9858, 0.9853, 0.9852, 0.9849, 0.9842, 0.9836, 0.9833, 0.9828, 0.9826, 0.9812, 0.9791, 0.9778, 0.9772, 0.976, 0.9759, 0.9756, 0.9737, 0.9705, 0.9704, 0.9686, 0.9683, 0.9675, 0.9673, 0.9669, 0.9667, 0.9667, 0.9661, 0.9216, 0.9296, 0.8828, 0.8547, 0.9269, 0.8685, 0.8949, 0.8805, 0.9015, 0.8908, 0.8539, 0.7304, 0.4984, 0.5004, 0.8091, 0.6634, 0.4073, 0.3766, 0.3312, 0.3658, -0.0834, -0.1632, 0.1976, 0.4369, -0.1391, 0.2407, 1.8703, 1.8701, 1.8692, 1.8667, 1.8637, 1.8632, 1.861, 1.8604, 1.8585, 1.8585, 1.8581, 1.8553, 1.8551, 1.8545, 1.8538, 1.8528, 1.8527, 1.8505, 1.8491, 1.8491, 1.8483, 1.8469, 1.8468, 1.844, 1.8431, 1.8421, 1.8407, 1.8404, 1.8404, 1.8404, 1.8203, 1.797, 1.8103, 1.6827, 1.7305, 1.7534, 1.7013, 1.5489, 1.6768, 1.5389, 1.3912, 1.321, 1.3801, 1.3865, 1.2998, 1.4923, 1.3784, 1.4465, 1.4777, 0.9736, 1.228, 1.1878, 1.4405, 1.4104, 0.9041, 0.5347, 0.7122, 0.3923, 0.2263, 0.7778, 0.893, 1.8866, 1.8861, 1.8813, 1.8812, 1.8804, 1.8785, 1.8757, 1.8756, 1.8755, 1.8745, 1.8742, 1.8738, 1.8721, 1.8715, 1.8704, 1.8703, 1.8699, 1.8695, 1.8692, 1.8682, 1.8677, 1.8672, 1.8671, 1.8669, 1.8664, 1.8661, 1.8661, 1.8654, 1.8636, 1.8626, 1.8454, 1.8148, 1.8075, 1.7359, 1.7708, 1.7842, 1.489, 1.4381, 1.8103, 1.1006, 1.3891, 1.0316, 1.5443, 1.311, 1.6366, 1.3213, 0.9024, 0.9642, 0.7957, 0.7401, 1.0385, 1.1641, 0.5105, 1.395, 1.1077, 0.9607, 0.8515, 1.0885, 0.4279, 1.0928, 0.8053, 1.1591, 0.5966, 0.0402, -1.2948, -2.0741, -1.5467, -0.4753, 2.0994, 2.0988, 2.0959, 2.0956, 2.0955, 2.0952, 2.0941, 2.094, 2.0932, 2.0922, 2.0921, 2.092, 2.0912, 2.0906, 2.0905, 2.0904, 2.0899, 2.0893, 2.0887, 2.0886, 2.0886, 2.088, 2.0875, 2.0871, 2.087, 2.0866, 2.0859, 2.0855, 2.0844, 2.084, 2.0763, 2.0301, 1.9622, 1.724, 1.8453, 1.7825, 1.8092, 1.7827, 1.8894, 1.8936, 1.787, 1.9709, 1.0995, 1.8065, 1.5724, 1.2914, 0.8085, 0.9436, 0.9345, 0.9806, 0.68, 0.6213, 0.9361, 1.1632, 0.095, 1.16, 0.6703, 0.7533, 1.0943, 0.1684, -0.153, 2.119, 2.112, 2.1114, 2.1114, 2.1107, 2.1096, 2.1092, 2.1087, 2.1072, 2.1065, 2.106, 2.1012, 2.0975, 2.0975, 2.0971, 2.0958, 2.0953, 2.0939, 2.0932, 2.0928, 2.0911, 2.0907, 2.0894, 2.0884, 2.0859, 2.0847, 2.084, 2.0839, 2.0837, 2.0833, 2.0618, 2.0121, 1.8787, 1.7452, 1.8761, 1.9526, 1.6129, 1.5087, 1.7379, 1.7929, 1.5277, 1.4588, 1.3717, 1.4829, 1.3781, 1.5634, 1.7476, 1.3585, 1.0791, 1.4302, 1.4594, 0.9242, 0.6272, 0.6829, 0.7599, 0.8213, 1.2604, 0.7533, 1.1565, 1.1451, 0.7746, -0.8785, 0.2398, 0.8293, 2.5102, 2.5076, 2.5012, 2.5007, 2.4983, 2.4952, 2.4946, 2.4825, 2.4819, 2.4746, 2.4724, 2.4697, 2.4678, 2.4662, 2.4646, 2.459, 2.4543, 2.4475, 2.4378, 2.4365, 2.4357, 2.4336, 2.4319, 2.4311, 2.43, 2.4294, 2.4289, 2.4261, 2.425, 2.4242, 2.1363, 2.1612, 2.3672, 2.0508, 2.0217, 1.7766, 1.725, 2.3465, 1.9799, 1.5261, 2.1049, 1.2632, 2.2185, 1.7089, 1.8898, 1.5832, 1.3163, 1.3231, 1.2305, 1.7242, 1.052, 0.7904, 1.4777, 1.5037, 0.0372, 1.1482, 1.1292, 0.5753, 0.4488, 0.823, -1.2462, 0.8876]}, \"token.table\": {\"Topic\": [3, 2, 4, 5, 5, 4, 3, 6, 3, 6, 5, 1, 2, 3, 4, 6, 2, 3, 4, 5, 4, 3, 2, 3, 4, 5, 3, 4, 4, 5, 4, 3, 4, 5, 6, 1, 6, 1, 1, 2, 3, 5, 4, 1, 1, 3, 1, 1, 1, 2, 4, 5, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 1, 6, 2, 3, 3, 2, 3, 5, 6, 5, 1, 1, 1, 1, 2, 5, 1, 5, 6, 4, 4, 4, 2, 3, 4, 3, 5, 4, 3, 1, 2, 3, 4, 6, 3, 1, 1, 2, 5, 1, 3, 1, 5, 4, 3, 1, 3, 6, 5, 4, 1, 3, 6, 3, 5, 6, 2, 2, 3, 4, 2, 3, 2, 4, 3, 4, 4, 2, 6, 6, 5, 1, 2, 4, 5, 1, 3, 1, 5, 6, 1, 4, 1, 2, 3, 4, 5, 1, 3, 5, 5, 6, 6, 2, 3, 6, 4, 5, 3, 6, 1, 1, 4, 2, 3, 6, 4, 1, 2, 3, 4, 5, 3, 5, 2, 2, 2, 4, 1, 5, 2, 2, 3, 1, 3, 6, 1, 2, 3, 4, 5, 6, 5, 5, 1, 2, 3, 4, 6, 2, 3, 3, 1, 2, 3, 4, 5, 4, 6, 3, 6, 1, 4, 6, 1, 6, 2, 2, 3, 4, 5, 6, 6, 1, 2, 3, 5, 2, 3, 5, 5, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 2, 4, 6, 2, 3, 4, 1, 4, 1, 1, 2, 4, 6, 1, 3, 4, 3, 2, 6, 2, 2, 3, 2, 3, 4, 1, 2, 3, 5, 6, 2, 3, 5, 6, 1, 6, 6, 2, 2, 5, 2, 3, 3, 4, 1, 2, 5, 2, 2, 1, 2, 3, 4, 6, 1, 1, 2, 4, 6, 1, 4, 2, 3, 4, 5, 6, 4, 6, 1, 5, 6, 6, 2, 4, 2, 3, 6, 1, 2, 5, 1, 2, 5, 1, 2, 3, 4, 5, 6, 3, 4, 6, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 6, 3, 3, 6, 1, 3, 2, 3, 4, 5, 2, 1, 3, 4, 3, 2, 1, 5, 1, 1, 3, 4, 2, 4, 2, 4, 6, 1, 4, 5, 6, 2, 2, 3, 5, 6, 1, 3, 4, 5, 6, 4, 2, 3, 2, 2, 6, 2, 3, 5, 6, 3, 4, 5, 6, 1, 2, 6, 1, 5, 6, 5, 3, 1, 3, 6, 5, 5, 2, 5, 2, 2, 6, 1, 2, 3, 6, 3, 4, 5, 1, 3, 6, 1, 5, 6, 5, 1, 2, 3, 5, 4, 5, 1, 3, 5, 6, 1, 6, 2, 1, 6, 6, 1, 2, 4, 3, 5, 5, 5, 2, 3, 2, 5, 6, 1, 2, 3, 4, 5, 6, 2, 3, 2, 5, 1, 2, 3, 4, 5, 6, 3, 3, 2, 3, 4, 2, 3, 3, 4, 4, 1, 5, 6, 2, 4, 5, 1, 2, 5, 3, 4, 3, 2, 3, 5, 5, 3, 2, 3, 1, 2, 2, 4, 5, 4, 4, 4, 3, 6, 1, 2, 6, 3, 6, 6, 1, 2, 3, 4, 5, 6, 2, 3, 4, 1, 5, 5, 2, 1, 2, 1, 2, 3, 4, 5, 6, 2, 6, 1, 2, 3, 5, 4, 1, 5, 3, 4, 6, 2, 3, 6, 4, 1, 2, 3, 2, 4, 2, 3, 4, 1, 1, 3, 5, 2, 5, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 6, 1, 1, 2, 3, 6, 2, 3, 4], \"Freq\": [0.9828773519467469, 0.18766329974629986, 0.3897622379346228, 0.4215206425070735, 0.9641915550737223, 0.9862733085833375, 0.9784441611324027, 0.9491312438777024, 0.9778295064851281, 0.9560575916397532, 0.9888135280355346, 0.5376978545997603, 0.034163123358548306, 0.08912119137012602, 0.060899480769586116, 0.27776104643689276, 0.12767985419771613, 0.3725930290678807, 0.22634155971413314, 0.27160987165695977, 0.9885571034214501, 0.9775067383805974, 0.2776807964987725, 0.3949769950198057, 0.1077209986417652, 0.2202295972231644, 0.2753027116607859, 0.724286328664618, 0.986603403009574, 0.9846355600278752, 0.9860004944558916, 0.14246300737383444, 0.26118218018536316, 0.49862052580842053, 0.09836731461526664, 0.9993070651908356, 0.9695754539749638, 0.9989306025014633, 0.45445380895538984, 0.011205710357804132, 0.06225394643224518, 0.47188491395641846, 0.9833034703757003, 0.9837528979864699, 0.8367763009940665, 0.15788232094227672, 0.9995183844176604, 0.986798937511041, 0.8884371653583382, 0.03388107833993662, 0.026351949819950708, 0.05144904488657043, 0.9873888431460012, 0.02430697075131326, 0.08507439762959641, 0.4496789588992953, 0.3311824764866432, 0.03646045612696989, 0.06988254091002562, 0.062352781534488824, 0.86727050679789, 0.06802121621944235, 0.5432530089884327, 0.455191448170673, 0.9263730135898215, 0.07237289168670481, 0.9974612038027201, 0.15537395667115783, 0.17822306794632808, 0.05026804480537459, 0.6123561821745632, 0.9839043130690119, 0.997654473454314, 0.9976774213280648, 0.9895303232484957, 0.06721767428931848, 0.379582160692622, 0.5515803272564663, 0.7239988501577403, 0.2753569397321242, 0.896802911639557, 0.992181375799463, 0.9817132313409164, 0.986295787442681, 0.9535726732501555, 0.22824492268515795, 0.7719294576205904, 0.9849620143776759, 0.9811464731755075, 0.9843132277878258, 0.9779369239344332, 0.977825910671496, 0.0495622697800196, 0.28593617180780534, 0.21349900828316135, 0.4498729103109471, 0.9692244071121122, 0.9957716047351054, 0.8993096476975009, 0.0796856649858545, 0.020870055115342845, 0.9864433228533858, 0.9895248814074977, 0.9720039046336681, 0.9784566916615451, 0.981144115014563, 0.9635906122722453, 0.12871172917431425, 0.16088966146789282, 0.7079145104587284, 0.9679289014427477, 0.9861768412166217, 0.23372429872348638, 0.1752932240426148, 0.584310746808716, 0.9684063228595539, 0.7170403638008565, 0.2715007202741107, 0.9854422560363559, 0.14885569510675714, 0.6376656128221894, 0.21121416197580406, 0.9776370114221201, 0.9820347448307698, 0.026673241899540862, 0.9709060051432874, 0.2712247219085033, 0.7275710794053502, 0.9828226697391531, 0.973105151636421, 0.91499622475905, 0.9142750665768031, 0.969048359303276, 0.5603991505167842, 0.09938702883096814, 0.03951532471592709, 0.3017533887398069, 0.9197509173040249, 0.08016177719622236, 0.9765528474162143, 0.9803706883663749, 0.939727843787347, 0.9976869602491791, 0.9781661137543992, 0.9978502061594006, 0.40608718713701714, 0.25167168110382365, 0.10408116981242876, 0.2371685672775016, 0.16852805292091538, 0.13788658875347623, 0.6894329437673812, 0.9559308421470797, 0.9563602233305237, 0.9355255583819977, 0.8405958489090064, 0.1553274938201425, 0.9551652325064517, 0.9879362657436204, 0.9743976163289945, 0.9877998105482518, 0.9833893599967881, 0.9984565255558173, 0.2726658533509695, 0.7245121246182904, 0.06363137188122094, 0.9271999902692193, 0.999210105400454, 0.9952780408899402, 0.1322437023933483, 0.0850138086814382, 0.4269582391556674, 0.09634898317229662, 0.25881981754126737, 0.0562642892037156, 0.9399445961091313, 0.9841776387009648, 0.9754517471173029, 0.18855506104738137, 0.8080931187744916, 0.9127640117770501, 0.08586328127146074, 0.9645461415682197, 0.990849760432185, 0.972250323681793, 0.9820257919356106, 0.9314976469942768, 0.0610818129176575, 0.12383696293261988, 0.312540906448993, 0.396573131296128, 0.04275323720292829, 0.09287772219946491, 0.03095924073315497, 0.9690222595077245, 0.9669923378813498, 0.19375148660645844, 0.11302170052043409, 0.21797042243226575, 0.11302170052043409, 0.36328403738710957, 0.5754933224345594, 0.4239580984798973, 0.9900915692853436, 0.14018191020953497, 0.37548725948982575, 0.2953833107986629, 0.0851104454843605, 0.10513643265715122, 0.36412671253654566, 0.6321644314870585, 0.23567249875216853, 0.7593891626458763, 0.11556156875219659, 0.8763418963708242, 0.9523235499275879, 0.9444307951456998, 0.05445366746786017, 0.9866086460857688, 0.9670744141746282, 0.3376035918834367, 0.44268550458887723, 0.1855701862670546, 0.03130099527396102, 0.9337014900284204, 0.12796869314660692, 0.07921871480504238, 0.6063278556232089, 0.1858592924272148, 0.6265946110371482, 0.3667870893875989, 0.9584370376659971, 0.9886534557207989, 0.9900388613902189, 0.9365391392257485, 0.013827593037251673, 0.01905965526756312, 0.0072252287942396135, 0.023295134215910476, 0.3425280318240909, 0.026295081230940313, 0.09410871177389164, 0.13424330944216897, 0.2242001662848595, 0.17922173786351425, 0.8195938945110837, 0.15441624099484183, 0.017817258576327905, 0.6137766964690596, 0.06064260773496697, 0.3252648960330047, 0.3164608097435875, 0.6827348950949619, 0.9978115111329248, 0.3844409652646629, 0.050144473730173424, 0.25815117957385575, 0.3045812478425349, 0.9894527601804338, 0.9884196965802514, 0.9764184346077442, 0.9850664391002991, 0.9855152539940755, 0.9436152283000769, 0.9918256167432021, 0.07044283561992076, 0.9245622175114601, 0.6845607854328989, 0.3124170027479002, 0.9958218902581383, 0.19157079142116354, 0.1450464563617381, 0.09304867011885086, 0.5281880392040652, 0.04105088387596362, 0.09767902823929152, 0.3943338547438065, 0.14832741325225748, 0.3545386950907618, 0.4531292170635135, 0.5390675168514212, 0.9311891120025156, 0.9908335675876118, 0.9753659818900825, 0.9624073604173291, 0.9477177776556661, 0.051879693302661754, 0.18634708105977638, 0.8119408531890256, 0.20844029671918227, 0.7149986922344044, 0.07513545579412384, 0.9535633637289299, 0.9862680662132346, 0.25473233070099566, 0.5234866245598443, 0.13320864999960325, 0.08646877280676, 0.9198225576301845, 0.9942555963306355, 0.4740669697417202, 0.035401104883310275, 0.1877797737288632, 0.30321815921791845, 0.13149634117740527, 0.8678758517708749, 0.16185099624562058, 0.5600558282784966, 0.05651939551434369, 0.14129848878585924, 0.07964096640657521, 0.9906582988927611, 0.9931909147849255, 0.6217834047435671, 0.3758963310495201, 0.9883880936212114, 0.9803439111081, 0.9351554937417774, 0.053437456785244426, 0.8263405048849403, 0.17204565716847336, 0.9521941660096261, 0.7740717240608751, 0.08315223598310181, 0.1421147305893013, 0.41490482687211155, 0.04318711952572165, 0.5413813911974392, 0.10463927295702533, 0.19257143510578612, 0.31655578373553883, 0.273469024282646, 0.0668284432330582, 0.04572472431735561, 0.565498794133535, 0.3624992270086763, 0.06669985776959644, 0.10248759435176195, 0.29496429593921736, 0.13498366085354013, 0.46494372071774936, 0.3122996488001509, 0.028279102056706574, 0.03934483764411349, 0.03442673293859931, 0.3516444864442644, 0.23238044733554533, 0.9798120486420763, 0.9763753378658279, 0.312097360111485, 0.6710093242396926, 0.9771547102535746, 0.9873669247225795, 0.7222653189720569, 0.15674694156414853, 0.07683673606085713, 0.044565306915297136, 0.9879970153097539, 0.6135255560758188, 0.020709723411841983, 0.3658717802758751, 0.9874047342268034, 0.9655673749771008, 0.9965623344744511, 0.9498356303628112, 0.9923693185729238, 0.09438961749522103, 0.8967013662045997, 0.9800040631624148, 0.9829878194840896, 0.9887906916280066, 0.6750238598578622, 0.32325086246714524, 0.9567066947346832, 0.13053750586783988, 0.05474153471877156, 0.5726806709040717, 0.24002057530538298, 0.9692039612776033, 0.09681074284267406, 0.670032246516402, 0.12228725411706197, 0.10954899847986801, 0.19144685083302448, 0.4545635483881556, 0.05694316588879703, 0.15217570194419897, 0.14432147216643385, 0.9739335541366191, 0.1406314715685672, 0.8569730298709565, 0.9928000885375042, 0.9861758626675147, 0.9924118032179419, 0.9966261235279517, 0.774614169343967, 0.2142549830100334, 0.9802090537043664, 0.07402492752790577, 0.7425625542643046, 0.06014525361642343, 0.12260378621809391, 0.5464433765470087, 0.20179859133893682, 0.25168138919799987, 0.26692648637328115, 0.4757318829717349, 0.256163321600165, 0.958072871912679, 0.9800162253004461, 0.1527394917887337, 0.45157762789712574, 0.395130424409985, 0.974983032535442, 0.9900703810755516, 0.6488915811814413, 0.34780588751325253, 0.953526268345413, 0.8851285932892536, 0.10213022230260618, 0.6148320073234678, 0.03816910112578575, 0.0593168463441265, 0.28729985577111705, 0.17438239861681107, 0.3098250383191886, 0.5146820308690346, 0.35364699465838684, 0.1855197349027603, 0.4580018455411895, 0.16387886397149606, 0.6844352554103659, 0.14941896420930523, 0.950187775778889, 0.9008190406154732, 0.007739398162017864, 0.04151131741445945, 0.049719770010539004, 0.9888786977347597, 0.9575767148544291, 0.8759275097831729, 0.032158570962514434, 0.007421208683657177, 0.08433191685974065, 0.5191781132898994, 0.48017881839488347, 0.984390296417887, 0.9949831520321195, 0.9433506392902373, 0.9534942514927857, 0.15753958889799827, 0.10025246566236252, 0.7447326020632645, 0.48020038503325735, 0.5168569029747274, 0.9846274468922978, 0.9548430223674376, 0.9744529595532159, 0.9927555613755762, 0.9575917486044234, 0.846249817706366, 0.15014109668983913, 0.10430506386361274, 0.22748437737873636, 0.3347695859241666, 0.14404032628784616, 0.06258303831816764, 0.12715283975754696, 0.9953157422633947, 0.9961233029594634, 0.09773790302340274, 0.8905008942132249, 0.027821157516133378, 0.25502727723122265, 0.1576532259247558, 0.15301636633873358, 0.20865868137100033, 0.19706653240594477, 0.9858798045366675, 0.9787826662321166, 0.6095791653506581, 0.15157103570881228, 0.2388891323671498, 0.28862634509010887, 0.7068400287921034, 0.9789857029098046, 0.9720451714983842, 0.9861589226174132, 0.9880089033132269, 0.6818600707317891, 0.3165778899826164, 0.06803232499686489, 0.9252396199573625, 0.9672759196962103, 0.11550418339562342, 0.5021921017201018, 0.38166599730727735, 0.41146041535813316, 0.5866366317977344, 0.9739190880526706, 0.652061518311399, 0.19645443179894714, 0.14629585346730106, 0.9904326957990718, 0.9907505554887093, 0.10593281303741235, 0.8898356295142638, 0.9804260219592944, 0.019229134806516775, 0.03736005491074422, 0.17612597315065134, 0.7845611531256287, 0.9841444877103716, 0.9883958669228502, 0.9693422595242576, 0.9902036775077716, 0.9595062118329337, 0.9785249439514042, 0.31081443231996797, 0.6889185871009599, 0.09208660920882578, 0.8748227874838449, 0.9957696819145935, 0.9413753201194446, 0.055158710163248706, 0.6101637015471937, 0.21717691072018758, 0.11375933418676493, 0.05687966709338246, 0.33427375409808824, 0.3542901465590516, 0.3102540831449322, 0.9815678818622248, 0.9959092241316446, 0.9828345693444998, 0.9717926213697247, 0.9097921743454546, 0.09022732307558227, 0.19637470028117213, 0.04560960780723998, 0.23184883968680323, 0.240717374538211, 0.2546536435904232, 0.031673338755027765, 0.13074416304737796, 0.8280463659667271, 0.3246341956136485, 0.26173632021350407, 0.157244688500361, 0.25564942904574817, 0.989328146350023, 0.21474848435755048, 0.7822980501596482, 0.9568184933422282, 0.041536306687724636, 0.961950443393492, 0.3636835199005027, 0.4849113598673369, 0.15086131195872704, 0.9875635365913357, 0.8764286839122664, 0.08648967275449997, 0.037478858193616654, 0.6077007016767372, 0.3869934816647878, 0.5638186139156365, 0.2449694667357593, 0.19053180746114612, 0.989071948316136, 0.2749599885540707, 0.12220443935736476, 0.6002394521376445, 0.9857572167392649, 0.9930162574513154, 0.1709038498067865, 0.45677938039268395, 0.20197727704438406, 0.16779650708302674, 0.9716264586533643, 0.3490521103307856, 0.09555799218181202, 0.026543886717170007, 0.10086676952524602, 0.05441496777019851, 0.3729416083762386, 0.9948544748371553, 0.576896752965075, 0.14736926399730887, 0.08985930731543225, 0.1851101730697904, 0.6167059984783908, 0.06906137900445634, 0.3125936102306971], \"Term\": [\"ability\", \"able\", \"able\", \"able\", \"account\", \"ad\", \"additional\", \"aged\", \"airdope\", \"airpod\", \"alexa\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"amazon\", \"amazon\", \"amazon\", \"amazon\", \"android\", \"answer\", \"app\", \"app\", \"app\", \"app\", \"apple\", \"apple\", \"assumption\", \"audible\", \"audiophile\", \"available\", \"available\", \"available\", \"available\", \"awesome\", \"awsome\", \"backup\", \"bad\", \"bad\", \"bad\", \"bad\", \"bag\", \"balanced\", \"base\", \"base\", \"bass\", \"basshead\", \"battery\", \"battery\", \"battery\", \"battery\", \"bed\", \"big\", \"big\", \"big\", \"big\", \"big\", \"big\", \"blue\", \"blue\", \"blue\", \"boat\", \"boat\", \"book\", \"book\", \"box\", \"brand\", \"brand\", \"brand\", \"brand\", \"bt\", \"bud\", \"build\", \"bullet\", \"button\", \"button\", \"button\", \"call\", \"call\", \"cancelation\", \"cancelling\", \"capacity\", \"card\", \"carousel\", \"case\", \"case\", \"casual\", \"category\", \"chance\", \"channel\", \"charging\", \"cheap\", \"cheap\", \"cheap\", \"cheap\", \"chromecast\", \"clarity\", \"clear\", \"clear\", \"clear\", \"colour\", \"comcast\", \"comfort\", \"command\", \"common\", \"compact\", \"company\", \"company\", \"company\", \"compatible\", \"complaint\", \"con\", \"con\", \"con\", \"connect\", \"connection\", \"connection\", \"consistent\", \"content\", \"content\", \"content\", \"contrast\", \"controller\", \"cord\", \"cord\", \"cover\", \"cover\", \"crazy\", \"current\", \"cute\", \"cx\", \"damage\", \"day\", \"day\", \"day\", \"day\", \"decent\", \"decent\", \"deep\", \"defective\", \"delicate\", \"delivery\", \"description\", \"design\", \"device\", \"device\", \"device\", \"device\", \"didn\", \"didn\", \"didn\", \"difficult\", \"disconnect\", \"disconnected\", \"display\", \"display\", \"disturbance\", \"download\", \"driver\", \"drop\", \"durable\", \"ear\", \"earbud\", \"earbud\", \"early\", \"early\", \"earphone\", \"earpod\", \"easy\", \"easy\", \"easy\", \"easy\", \"easy\", \"echo\", \"echo\", \"edge\", \"email\", \"end\", \"end\", \"excellent\", \"excellent\", \"excited\", \"eye\", \"fabric\", \"fabulous\", \"fan\", \"fan\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feedback\", \"feeling\", \"fine\", \"fine\", \"fine\", \"fine\", \"fine\", \"fire\", \"fire\", \"firetv\", \"first\", \"first\", \"first\", \"first\", \"first\", \"fit\", \"fit\", \"fitting\", \"fitting\", \"flat\", \"flat\", \"flipcart\", \"flipkart\", \"flipkart\", \"following\", \"font\", \"free\", \"free\", \"free\", \"free\", \"frequency\", \"game\", \"game\", \"game\", \"game\", \"generation\", \"generation\", \"genre\", \"gift\", \"gig\", \"good\", \"good\", \"good\", \"good\", \"good\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"hd\", \"hd\", \"hd\", \"hdx\", \"hdx\", \"hdx\", \"headphone\", \"headphone\", \"headset\", \"high\", \"high\", \"high\", \"high\", \"hrs\", \"huge\", \"ignorance\", \"immediate\", \"inch\", \"indicator\", \"ink\", \"interface\", \"interface\", \"ipad\", \"ipad\", \"iphone\", \"issue\", \"issue\", \"issue\", \"issue\", \"issue\", \"item\", \"item\", \"item\", \"item\", \"jbl\", \"jbl\", \"just\", \"keyboard\", \"killer\", \"kind\", \"kindle\", \"kindle\", \"large\", \"large\", \"last\", \"last\", \"last\", \"leap\", \"left\", \"light\", \"light\", \"light\", \"light\", \"listening\", \"loud\", \"low\", \"low\", \"low\", \"low\", \"magnet\", \"magnet\", \"many\", \"many\", \"many\", \"many\", \"many\", \"metal\", \"mi\", \"mic\", \"mic\", \"mid\", \"min\", \"mini\", \"mini\", \"model\", \"model\", \"mom\", \"money\", \"money\", \"money\", \"month\", \"month\", \"month\", \"more\", \"more\", \"more\", \"more\", \"more\", \"more\", \"most\", \"most\", \"most\", \"movie\", \"movie\", \"movie\", \"movie\", \"music\", \"music\", \"music\", \"music\", \"music\", \"music\", \"musician\", \"navigation\", \"neck\", \"neck\", \"neckband\", \"negative\", \"new\", \"new\", \"new\", \"new\", \"nexus\", \"nice\", \"nice\", \"nice\", \"niche\", \"night\", \"noise\", \"none\", \"normal\", \"note\", \"note\", \"number\", \"oasis\", \"offering\", \"old\", \"old\", \"ondemand\", \"only\", \"only\", \"only\", \"only\", \"operating\", \"option\", \"option\", \"option\", \"option\", \"other\", \"other\", \"other\", \"other\", \"other\", \"outside\", \"own\", \"own\", \"page\", \"pain\", \"pair\", \"paperwhite\", \"past\", \"past\", \"penny\", \"people\", \"people\", \"people\", \"people\", \"perfect\", \"perfect\", \"perfect\", \"phone\", \"phone\", \"phone\", \"physical\", \"pleasant\", \"point\", \"point\", \"point\", \"policy\", \"portable\", \"power\", \"power\", \"ppi\", \"previous\", \"previous\", \"price\", \"price\", \"price\", \"price\", \"prime\", \"prime\", \"prime\", \"pro\", \"pro\", \"pro\", \"problem\", \"problem\", \"problem\", \"process\", \"product\", \"product\", \"product\", \"product\", \"public\", \"pure\", \"quality\", \"quality\", \"quality\", \"quality\", \"range\", \"range\", \"reading\", \"realme\", \"redmi\", \"refund\", \"regular\", \"regular\", \"regular\", \"remote\", \"remote\", \"replacement\", \"request\", \"resolution\", \"response\", \"result\", \"return\", \"return\", \"review\", \"review\", \"review\", \"review\", \"review\", \"review\", \"right\", \"roku\", \"room\", \"room\", \"same\", \"same\", \"same\", \"same\", \"same\", \"same\", \"saver\", \"scratch\", \"screen\", \"screen\", \"screen\", \"search\", \"search\", \"secondary\", \"section\", \"secure\", \"segment\", \"service\", \"service\", \"set\", \"set\", \"shopping\", \"side\", \"side\", \"side\", \"simple\", \"simple\", \"site\", \"size\", \"size\", \"size\", \"sling\", \"smart\", \"smartphone\", \"smartphone\", \"sound\", \"sound\", \"speaker\", \"speaker\", \"speaker\", \"specific\", \"step\", \"stock\", \"streaming\", \"sturdy\", \"stylish\", \"such\", \"such\", \"suggestion\", \"suggestion\", \"super\", \"superb\", \"superb\", \"sure\", \"sure\", \"sure\", \"sure\", \"tablet\", \"tablet\", \"tablet\", \"tangle\", \"tap\", \"team\", \"text\", \"thank\", \"thank\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"tight\", \"tight\", \"time\", \"time\", \"time\", \"time\", \"title\", \"top\", \"top\", \"tv\", \"tv\", \"uncomfortable\", \"user\", \"user\", \"user\", \"validity\", \"value\", \"value\", \"value\", \"version\", \"version\", \"video\", \"video\", \"video\", \"vocal\", \"voice\", \"voice\", \"voice\", \"voyage\", \"waste\", \"way\", \"way\", \"way\", \"way\", \"weather\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"wire\", \"worth\", \"worth\", \"worth\", \"worth\", \"year\", \"year\", \"year\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5, 6]};\n\nfunction LDAvis_load_lib(url, callback){\n  var s = document.createElement('script');\n  s.src = url;\n  s.async = true;\n  s.onreadystatechange = s.onload = callback;\n  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n  document.getElementsByTagName(\"head\")[0].appendChild(s);\n}\n\nif(typeof(LDAvis) !== \"undefined\"){\n   // already loaded: just create the visualization\n   !function(LDAvis){\n       new LDAvis(\"#\" + \"ldavis_el271401164527291685618773790\", ldavis_el271401164527291685618773790_data);\n   }(LDAvis);\n}else if(typeof define === \"function\" && define.amd){\n   // require.js is available: use it to load d3/LDAvis\n   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n   require([\"d3\"], function(d3){\n      window.d3 = d3;\n      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n        new LDAvis(\"#\" + \"ldavis_el271401164527291685618773790\", ldavis_el271401164527291685618773790_data);\n      });\n    });\n}else{\n    // require.js not available: dynamically load d3 & LDAvis\n    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n                 new LDAvis(\"#\" + \"ldavis_el271401164527291685618773790\", ldavis_el271401164527291685618773790_data);\n            })\n         });\n}\n</script>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n  from imp import reload\n/opt/conda/lib/python3.7/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n  from imp import reload\n/opt/conda/lib/python3.7/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n  from imp import reload\n/opt/conda/lib/python3.7/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n  from imp import reload\n","output_type":"stream"}]},{"cell_type":"markdown","source":"References:\n(2022, November 10). Modeling a topic using LDA. Kaggle. Retrieved November 28, 2022, from https://www.kaggle.com/code/vivekgediya/topic-modeling-using-lda-on-product-review \nNatural language processing corpora - NLP-for-hackers. NLP. (2018, June 22). Retrieved November 28, 2022, from https://nlpforhackers.io/corpora/ ","metadata":{}}]}